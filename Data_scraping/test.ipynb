{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# pass a url and file save path to save all html data to a file\n",
    "def get_html(url, path):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(path, 'w', encoding='utf-8') as file:\n",
    "            file.write(response.text)\n",
    "    else: \n",
    "        print(\"Failed to retrieve the page. Status code:\", response.status_code)\n",
    "        \n",
    "# pass alphabet range and year range for search for player metrics/statistics\n",
    "def find_players(start_letter, end_letter):\n",
    "    all_players_url = \"https://www.basketball-reference.com/players/\"\n",
    "    # create array of letters\n",
    "    alphabet_range = [chr(i) for i in range(ord(start_letter), ord(end_letter) + 1)]\n",
    "\n",
    "    for letter in alphabet_range:\n",
    "        # concatenate each letter to make the new url's to browse through all players\n",
    "        new_url = f\"https://www.basketball-reference.com/players/{letter}\"\n",
    "        # pass the url information to save the html data\n",
    "        get_html(new_url, rf'C:\\Users\\Michael\\Code\\Python\\Data_scraping\\player_page_html\\letter_{letter}_data.html')\n",
    "        # sets a delay of a few seconds to try and space the number of requests to avoid 426 error\n",
    "        time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Kareem Abdul-Jabbar', '/players/a/abdulka01.html'], ['Tom Abernethy', '/players/a/abernto01.html'], ['Alvan Adams', '/players/a/adamsal01.html'], ['Darrell Allums', '/players/a/allumda01.html'], ['Tiny Archibald', '/players/a/architi01.html'], ['Dennis Awtrey', '/players/a/awtrede01.html'], ['Gus Bailey', '/players/b/bailegu01.html'], ['James Bailey', '/players/b/baileja01.html'], ['Greg Ballard', '/players/b/ballagr01.html'], ['Mike Bantom', '/players/b/bantomi01.html'], ['Marvin Barnes', '/players/b/barnema01.html'], ['Rick Barry', '/players/b/barryri01.html'], ['Tim Bassett', '/players/b/basseti01.html'], ['Billy Ray Bates', '/players/b/batesbi01.html'], ['Ron Behagen', '/players/b/behagro01.html'], ['Mel Bennett', '/players/b/benneme01.html'], ['Kent Benson', '/players/b/bensoke01.html'], ['Del Beshore', '/players/b/beshode01.html'], ['Henry Bibby', '/players/b/bibbyhe01.html'], ['Larry Bird', '/players/b/birdla01.html'], ['Otis Birdsong', '/players/b/birdsot01.html'], ['Norman Black', '/players/b/blackno01.html'], ['Ron Boone', '/players/b/boonero01.html'], ['Lawrence Boston', '/players/b/bostola01.html'], ['Tom Boswell', '/players/b/bosweto01.html'], ['Winford Boynes', '/players/b/boynewi01.html'], ['Alonzo Bradley', '/players/b/bradlal01.html'], ['Dudley Bradley', '/players/b/bradldu01.html'], ['Mike Bratz', '/players/b/bratzmi01.html'], ['Jim Brewer', '/players/b/breweji01.html'], ['Ron Brewer', '/players/b/brewero01.html'], ['Junior Bridgeman', '/players/b/bridgju01.html'], ['Allan Bristow', '/players/b/bristal01.html'], ['Dave Britton', '/players/b/brittda01.html'], ['Michael Brooks', '/players/b/brookmi01.html'], ['Fred Brown', '/players/b/brownfr01.html'], ['John Brown', '/players/b/brownjo01.html'], ['Lewis Brown', '/players/b/brownle02.html'], ['Rickey Brown', '/players/b/brownri01.html'], ['Roger Brown', '/players/b/brownro02.html'], ['Joe Bryant', '/players/b/bryanjo01.html'], ['Quinn Buckner', '/players/b/bucknqu01.html'], ['Tom Burleson', '/players/b/burleto01.html'], ['Don Buse', '/players/b/busedo01.html'], ['Marty Byrnes', '/players/b/byrnema01.html']]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# find players based on the seasons that they have played, pulling from html data already saved using the find_players function\n",
    "def find_players_by_year(start_letter, end_letter, start_year, end_year):\n",
    "    # create array of letters\n",
    "    alphabet_range = [chr(i) for i in range(ord(start_letter), ord(end_letter) + 1)]\n",
    "    \n",
    "    # empty array to collect player names\n",
    "    player_names_with_url = []\n",
    "    \n",
    "    # take data from saved location\n",
    "    for letter in alphabet_range:\n",
    "        # open file containing the HTML data\n",
    "        with open(rf'C:\\Users\\Michael\\Code\\Python\\Data_scraping\\alphabetic_players_grouped\\letter_{letter}_data', 'r', encoding='utf-8') as file:\n",
    "            contents = file.read()\n",
    "        \n",
    "        soup = BeautifulSoup(contents, \"html.parser\")   \n",
    "        table = soup.find(\"table\", id=\"players\").find(\"tbody\")\n",
    "        \n",
    "        # iterates through the table data for players of a given last name starting letter\n",
    "        for element in table.find_all(\"tr\"):\n",
    "            # gets the years played bounds\n",
    "            lower_year_bound = int(element.find('td', {'data-stat': 'year_min'}).get_text())\n",
    "            upper_year_bound = int(element.find('td', {'data-stat': 'year_max'}).get_text())\n",
    "            \n",
    "            # checks the years played by the player\n",
    "            if (lower_year_bound >= start_year or upper_year_bound >= start_year) and ( lower_year_bound <= end_year) :\n",
    "                # if the player played during the years specified, add to the list\n",
    "                player_names_with_url.append([element.find('th', {'data-stat': 'player'}).find('a').get_text(), element.find('th', {'data-stat': 'player'}).find('a')['href']])\n",
    "    return player_names_with_url\n",
    "                \n",
    "player_list = find_players_by_year('a', 'b', 1980, 1981)\n",
    "print(player_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataFrame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m player_names_with_url\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# retrieve the player metrics by passing the list containing the names and url\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_player_metrics\u001b[39m(player_names_with_url: \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m     42\u001b[0m     baseline_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.basketball-reference.com\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m player \u001b[38;5;129;01min\u001b[39;00m player_names_with_url: \n\u001b[0;32m     45\u001b[0m         \u001b[38;5;66;03m# pass the full url after appending to the end of the baseline url from list\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DataFrame' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "\n",
    "# find players based on the seasons that they have played, pulling from html data already saved using the find_players function\n",
    "def find_players_by_year(start_letter: str, end_letter: str, start_year: int, end_year: int) -> list :\n",
    "    # create array of letters\n",
    "    alphabet_range = [chr(i) for i in range(ord(start_letter), ord(end_letter) + 1)]\n",
    "    \n",
    "    # empty array to collect player names\n",
    "    player_names_with_url = []\n",
    "    \n",
    "    # take data from saved location\n",
    "    for letter in alphabet_range:\n",
    "        \n",
    "        # open file containing the HTML data (with error handles)\n",
    "        with open(rf'C:\\Users\\Michael\\Code\\Python\\Data_scraping\\alphabetic_players_grouped\\letter_{letter}_data', 'r', encoding='utf-8') as file:\n",
    "            contents = file.read()\n",
    "        \n",
    "        soup = BeautifulSoup(contents, \"html.parser\")\n",
    "        table = soup.find(\"table\", id=\"players\").find(\"tbody\")\n",
    "        \n",
    "        # iterates through the table data for players of a given last name starting letter\n",
    "        for element in table.find_all(\"tr\"):\n",
    "            # gets the years played bounds\n",
    "            lower_year_bound = int(element.find('td', {'data-stat': 'year_min'}).get_text())\n",
    "            upper_year_bound = int(element.find('td', {'data-stat': 'year_max'}).get_text())\n",
    "            \n",
    "            # checks the years played by the player\n",
    "            if (lower_year_bound >= start_year or upper_year_bound >= start_year) and ( lower_year_bound <= end_year) :\n",
    "                # if the player played during the years specified, create a list containing the name and url, then add that list to player_names_with_url\n",
    "                player_names_with_url.append([element.find('th', {'data-stat': 'player'}).find('a').get_text(), element.find('th', {'data-stat': 'player'}).find('a')['href']])\n",
    "    \n",
    "    # returns a list containing the player name with part of the url to navigate to their data page\n",
    "    return player_names_with_url\n",
    "\n",
    "# retrieve the player metrics by passing the list containing the names and url\n",
    "def get_player_metrics(player_names_with_url: list) -> DataFrame:\n",
    "    \n",
    "    baseline_url = \"https://www.basketball-reference.com\"\n",
    "    \n",
    "    for player in player_names_with_url: \n",
    "        # pass the full url after appending to the end of the baseline url from list\n",
    "        page_data = get_response_data(f'{baseline_url}{player[1]}')\n",
    "        # make the soup\n",
    "        soup = BeautifulSoup(page_data, 'html.parser')\n",
    "        \n",
    "        # find specific branch of HTML data\n",
    "        full_player_stats = soup.find('div', id='meta')\n",
    "        \n",
    "        # retrieve the str of data, ensure a space between lines/words, replace strange characters \n",
    "        player_metric_string = full_player_stats.get_text(separator=\" \").replace(u'\\xa0', ' ').replace(u'\\u25aa', '').strip()\n",
    "        \n",
    "        # normalize whitespace to a single space; split() breaks the string into words by whitespace; join() fuses them back together with only a single whitespace between each word\n",
    "        single_line_output = ' '.join(player_metric_string.split())\n",
    "        \n",
    "        # array of strings containing player info, starting with their name\n",
    "        player_metrics = [player[0]]\n",
    "        \n",
    "        # use re to collect the text between \"Position:\" and \"Shoots:\" to get player position\n",
    "        position = re.search(r'Position:\\s*(.*?)\\s*Shoots:', single_line_output)\n",
    "        if position:\n",
    "            # assigns the first instance this pattern is found within the given string\n",
    "            player_metrics.append(position.group(1))\n",
    "        \n",
    "        # use re to collect the text immediately after \"Shoots:\" for player dominant shooting hand\n",
    "        shoots = re.search(r'Shoots:\\s*(\\w+)', single_line_output)\n",
    "        if shoots:\n",
    "            player_metrics.append(shoots.group(1))\n",
    "        \n",
    "        # use re to collect the number for height\n",
    "        height = re.search(r'(\\d+)cm', single_line_output)\n",
    "        if height:\n",
    "            player_metrics.append(height.group(1))\n",
    "        \n",
    "        # use re to collect the number for weight\n",
    "        weight = re.search(r'(\\d+)kg', single_line_output)\n",
    "        if weight:\n",
    "            player_metrics.append(weight.group(1))\n",
    "        \n",
    "        # use re to collect the text for college\n",
    "        college = re.search(r'College:\\s*(\\w+)', single_line_output)\n",
    "        if college:\n",
    "            player_metrics.append(college.group(1))\n",
    "        else:\n",
    "            player_metrics.append(\"n/a\")\n",
    "        \n",
    "        player_metric_headers = ['Name','Position','Shoots', 'Height', 'Weight', 'College']\n",
    "        \n",
    "        # create the DataFrame containing player info\n",
    "        player_metrics_df = pd.DataFrame([player_metrics], columns=player_metric_headers)\n",
    "        \n",
    "    return player_metrics_df\n",
    "\n",
    "\n",
    "player_list = find_players_by_year('a', 'b', 1980, 1985)\n",
    "data_frame = get_player_metrics(player_list)\n",
    "#print(player_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
